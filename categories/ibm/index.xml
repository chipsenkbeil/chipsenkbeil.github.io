<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ibm on Senkbeil</title>
    <link>http://chipsenkbeil.com/categories/ibm/</link>
    <description>Recent content in Ibm on Senkbeil</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Copyright &amp;#169; by Chip Senkbeil</copyright>
    <lastBuildDate>Wed, 29 Jul 2015 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://chipsenkbeil.com/categories/ibm/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Overview of the Spark Kernel Client Library</title>
      <link>http://chipsenkbeil.com/post/overview-of-the-spark-kernel-client-library/</link>
      <pubDate>Wed, 29 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>http://chipsenkbeil.com/post/overview-of-the-spark-kernel-client-library/</guid>
      <description>&lt;p&gt;In this third and final part of the Spark Kernel series (part 1, part 2), we
will focus on the client library, a Scala-based library used to interface with
the Spark Kernel. This library enables Scala applications to quickly
communicate with a Spark Kernel without needing to understand ZeroMQ or the
IPython message protocol. Furthermore, using the client library, Scala
applications are able to treat the Spark Kernel as a remote service, meaning
that they can run separately from a Spark cluster and use the kernel as a
remote connection into the cluster.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Spark Kernel Architecture</title>
      <link>http://chipsenkbeil.com/post/spark-kernel-architecture/</link>
      <pubDate>Wed, 22 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>http://chipsenkbeil.com/post/spark-kernel-architecture/</guid>
      <description>&lt;p&gt;In the first part of the Spark Kernel series, we stepped through the problem
with enabling interactive applications against Apache Spark and how the Spark
Kernel solved this problem. This week, we will focus on the Spark Kernel’s
architecture: how we achieve fault tolerance and scalability using Akka, why
we chose ZeroMQ with the IPython/Jupyter message protocol, what the layers of
functionality are in the kernel (see figure 1 below), and elaborate on an
interactive API from IPython called the Comm API.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to enable interactive applications against Apache Spark</title>
      <link>http://chipsenkbeil.com/post/how-to-enable-interactive-applications-against-apache-spark/</link>
      <pubDate>Wed, 15 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>http://chipsenkbeil.com/post/how-to-enable-interactive-applications-against-apache-spark/</guid>
      <description>&lt;p&gt;Last December, IBM open sourced a project called the Spark Kernel, an
application focused on interactive usage of Apache Spark. This project
addresses a problem we encountered when trying to migrate a Storm-based
application to Apache Spark, “How do we enable interactive applications
against Apache Spark?”&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>